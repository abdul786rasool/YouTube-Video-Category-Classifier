{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2\n"],"metadata":{"id":"lWLSOigoXbWS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703312083865,"user_tz":-330,"elapsed":19392,"user":{"displayName":"Abdul rasool","userId":"04117823616186371888"}},"outputId":"8a94b2f2-9caa-4cff-ec2a-e94e936a18cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n","Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.0)\n","Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.1.1)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.62.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.3)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.31.0)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.1.1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2023.11.17)\n"]}]},{"cell_type":"code","source":["# Set your API key\n","API_KEY ='AIzaSyBIzk_AgfB4Y1UxLYO96El9CME4DaUHgNE'"],"metadata":{"id":"pJCYli06-b96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from googleapiclient.discovery import build\n","\n","\n","# Create a YouTube API client\n","youtube = build('youtube', 'v3', developerKey=API_KEY)\n","\n","def get_video_urls(query, max_results=1000):\n","    # Initialize an empty list to store video URLs\n","    video_urls = []\n","    # Initialize a variable for pagination\n","    next_page_token = None\n","\n","    # Loop until the list of video URLs reaches the maximum number of results requested\n","    while len(video_urls) < max_results:\n","        # Create a search request with the specified query and a dynamic number of results\n","        request = youtube.search().list(\n","            q=query,\n","            type='video',\n","            part='id',\n","            maxResults=min(50, max_results - len(video_urls)),\n","            pageToken=next_page_token\n","        )\n","        # Execute the search request and store the response\n","        response = request.execute()\n","        # Extract the list of items (videos) from the response\n","        items = response.get('items', [])\n","\n","        # Loop through each item (video) in the response\n","        for item in items:\n","            # Extract the video ID\n","            video_id = item['id']['videoId']\n","            # Form the complete URL of the video and add it to the list\n","            video_url = f'https://www.youtube.com/watch?v={video_id}'\n","            video_urls.append(video_url)\n","\n","        # Update the next_page_token for pagination\n","        next_page_token = response.get('nextPageToken')\n","\n","        # Break the loop if there are no more pages to retrieve\n","        if not next_page_token:\n","            break\n","\n","    # Return the list of video URLs\n","    return video_urls\n"],"metadata":{"id":"DLHCTLqTXeQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from googleapiclient.discovery import build\n","\n","# Create a YouTube API client using the API key\n","youtube = build('youtube', 'v3', developerKey=API_KEY)\n","\n","def get_video_details(VIDEO_URL):\n","    # Extract the video ID from the video URL\n","    video_id = VIDEO_URL.split('v=')[1]\n","\n","    # Create a request to get details of the video using the YouTube Data API\n","    request = youtube.videos().list(\n","        part='snippet,contentDetails,statistics',\n","        id=video_id\n","    )\n","    # Execute the request and store the response\n","    response = request.execute()\n","    # Return the first item from the response if it exists, otherwise return None\n","    return response['items'][0] if response['items'] else None\n","\n","def get_video_comments(VIDEO_URL, max_results=50):\n","    # Extract the video ID from the video URL\n","    video_id = VIDEO_URL.split('v=')[1]\n","\n","    try:\n","        # Create a request to get comments of the video sorted by relevance\n","        request = youtube.commentThreads().list(\n","            part='snippet',\n","            videoId=video_id,\n","            order='relevance',\n","            textFormat='plainText',\n","            maxResults=max_results\n","        )\n","        # Execute the request and store the response\n","        response = request.execute()\n","        # Return a list of comments extracted from the response\n","        return [comment['snippet']['topLevelComment']['snippet']['textDisplay'] for comment in response['items']]\n","    except:\n","        # In case of any error, return None\n","        return None\n"],"metadata":{"id":"A12vVI8VXtdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categories = ['music','sports','gaming','education','film/animation','entertainment','news and politics','comedy','other']\n","category_ids=[[10],[17],[20],[27],[1,18,30,31,41,44],[24,36,43],[25],[23,34],[-1]]\n","category_label = [i for i in range(len(categories))]"],"metadata":{"id":"tBsVl-afne71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["category_with_ids={}\n","for key,value in zip(categories,category_ids):\n","  category_with_ids[key]=value\n","category_with_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XRgGEmaUzkun","executionInfo":{"status":"ok","timestamp":1702886473912,"user_tz":-330,"elapsed":351,"user":{"displayName":"Abdul rasool","userId":"04117823616186371888"}},"outputId":"fbc5cedc-bc00-41d3-c2e7-c04173cf29b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'music': [10],\n"," 'sports': [17],\n"," 'gaming': [20],\n"," 'education': [27],\n"," 'film/animation': [1, 18, 30, 31, 41, 44],\n"," 'entertainment': [24, 36, 43],\n"," 'news and politics': [25],\n"," 'comedy': [23, 34],\n"," 'other': [-1]}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["category_to_label = {}\n","for value in category_label:\n","  category_to_label[categories[value]] = value\n","category_to_label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihVia2oa5t3y","executionInfo":{"status":"ok","timestamp":1702886476680,"user_tz":-330,"elapsed":3,"user":{"displayName":"Abdul rasool","userId":"04117823616186371888"}},"outputId":"5d1c703d-612e-4b20-d7f8-814b8c040cba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'music': 0,\n"," 'sports': 1,\n"," 'gaming': 2,\n"," 'education': 3,\n"," 'film/animation': 4,\n"," 'entertainment': 5,\n"," 'news and politics': 6,\n"," 'comedy': 7,\n"," 'other': 8}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def get_video_data(VIDEO_URL, get_video_details=get_video_details, get_video_comments=get_video_comments):\n","    # Retrieve video details using the get_video_details function\n","    video_details = get_video_details(VIDEO_URL)\n","\n","    # If video details are not found, return a list of None values and default counts\n","    if not video_details:\n","        return [None] * 12\n","\n","    # Retrieve video comments using the get_video_comments function\n","    video_comments = get_video_comments(VIDEO_URL)\n","\n","    # Extract various details from the video_details dictionary\n","    video_id = video_details.get('id', None)\n","    title = video_details['snippet'].get('title', None)\n","    description = video_details['snippet'].get('description', None)\n","    tags = video_details['snippet'].get('tags', None)\n","    category_Id = video_details['snippet'].get('categoryId', -1)\n","    statistics = video_details['statistics']\n","    viewCount = statistics.get('viewCount', 0)\n","    likeCount = statistics.get('likeCount', 0)\n","    dislikeCount = statistics.get('dislikeCount', 0)\n","    commentCount = statistics.get('commentCount', 0)\n","\n","    # Initialize category as 'other'\n","    category = 'other'\n","\n","    # Loop through the category_with_ids to match the category ID\n","    for cat, id in category_with_ids.items():\n","        if int(category_Id) in id:\n","            category = cat\n","            break\n","\n","    # Map the category to a category label\n","    category_label = category_to_label[category]\n","\n","    # Return a list of collected video data\n","    return [video_id, category_Id, category, category_label, title, description, tags, viewCount, likeCount, dislikeCount, commentCount, video_comments]\n"],"metadata":{"id":"KRXaa80t0CHI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize an empty dictionary to store URLs categorized by video type\n","URLS = {}\n","\n","# Note: Before executing the code, be aware of your API quota limitations as scraping a large number of videos can quickly consume the available quota.\n","\n","# Scraping URLs for music, sports, gaming, and education videos\n","# Looping through the first four categories in the 'categories' list\n","for cat in categories[:4]:\n","    # Fetching 1000 video URLs for each category and adding them to the URLS dictionary\n","    URLS[cat] = get_video_urls(f\"top english {cat} videos\", 1000)\n","\n","# Scraping URLs for film and animation videos\n","# Fetching URLs for different sub-categories within film and animation and combining them\n","URLS['film/animation'] = get_video_urls(f\"top english movies scenes\", 400)\n","URLS['film/animation'] += get_video_urls(f\"top english movie trailers\", 400)\n","URLS['film/animation'] += get_video_urls(f\"top english animation scenes\", 200)\n","\n","# Scraping URLs for entertainment videos\n","# Fetching URLs for general entertainment and entertainment shows\n","URLS['entertainment'] = get_video_urls(f\"top english entertainment videos\", 600)\n","URLS['entertainment'] += get_video_urls(f\"top english entertainment shows\", 400)\n","\n","# Scraping URLs for news and politics, and comedy videos\n","# Fetching 1000 video URLs for each of these two categories\n","URLS['news and politics'] = get_video_urls(f\"top english news and politics videos\", 1000)\n","URLS['comedy'] = get_video_urls(f\"top english comedy videos\", 1000)\n","\n","# Scraping URLs for 'other' videos\n","# Define a list of categories to be included in 'other'\n","other_videos = ['Vehicles', 'Pets & Animals', 'Travel & Events', 'Documentary', 'Fashion and style']\n","URLS['other'] = []\n","# Looping through each category in 'other_videos' and fetching URLs\n","for cat in other_videos:\n","    URLS['other'] += get_video_urls(f\"{cat} videos in english\", 200)\n"],"metadata":{"id":"fB6cDdarG4jI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["URLS.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3sETGZaMutp","executionInfo":{"status":"ok","timestamp":1702887084539,"user_tz":-330,"elapsed":436,"user":{"displayName":"Abdul rasool","userId":"04117823616186371888"}},"outputId":"604ccbff-2c46-455a-89b8-4974660e5c29"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['music', 'sports', 'gaming', 'education', 'film/animation', 'entertainment', 'news and politics', 'comedy', 'other'])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["corpus=[]\n","for _,url in URLS_EXTRA:\n","  corpus.append(get_video_data(url))"],"metadata":{"id":"2ADqNdJDwM2g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_count = {}\n","for cat in categories:cat_count[cat]=0\n","for data in corpus:cat_count[data[2]]+=1\n","cat_count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOXgjPFMrpCk","executionInfo":{"status":"ok","timestamp":1702898870881,"user_tz":-330,"elapsed":9,"user":{"displayName":"Abdul rasool","userId":"04117823616186371888"}},"outputId":"051eb511-f9e7-4f41-fd02-b24fe5a00f72"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'music': 672,\n"," 'sports': 306,\n"," 'gaming': 410,\n"," 'education': 1322,\n"," 'film/animation': 677,\n"," 'entertainment': 1269,\n"," 'news and politics': 545,\n"," 'comedy': 341,\n"," 'other': 1253}"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"kDn_3MsYrqeX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["youtube_dataframe = pd.DataFrame(data=corpus,columns=[\"video_id\",\"category_Id\",\"category\",\"category_label\",\"title\",\"description\",\"tags\",\"viewCount\",\"likeCount\",\"dislikeCount\",\"commentCount\",\"video_comments\"])"],"metadata":{"id":"ViqxJEr-sFVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["youtube_dataframe.shape"],"metadata":{"id":"igLoQokjsfhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["youtube_dataframe.sort_values(by=['category_label'],inplace=True)"],"metadata":{"id":"iFGcTTPLsu0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["youtube_dataframe.to_csv('youtube_data.csv')"],"metadata":{"id":"JJ93f_uRtgTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["youtube_dataframe.to_excel('youtube_data.xlsx')"],"metadata":{"id":"HRRD5-qouNrw"},"execution_count":null,"outputs":[]}]}