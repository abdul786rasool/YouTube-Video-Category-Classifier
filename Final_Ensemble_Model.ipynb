{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECn6fG4MBznp","outputId":"ebd6a2e1-a92c-4ff2-d768-30f452c3e2f9","executionInfo":{"status":"ok","timestamp":1703559788539,"user_tz":-330,"elapsed":37279,"user":{"displayName":"abdul rasool","userId":"13975637965595716262"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","# Append the directory to your python path using os\n","os.chdir('/content/drive/MyDrive/Youtube_video_classifier')"],"metadata":{"id":"hD_021jKB4r6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","import tensorflow as tf\n","import pickle\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import re\n","\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","eng_stopwords=stopwords.words('english')\n","lemmatizer = WordNetLemmatizer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1iGB1hmCbNb","outputId":"ea185b85-0f8c-47e7-95f0-f24cb93065ce","executionInfo":{"status":"ok","timestamp":1703561090663,"user_tz":-330,"elapsed":5920,"user":{"displayName":"abdul rasool","userId":"13975637965595716262"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    device_name = torch.device(\"cuda\")\n","else:\n","    device_name = torch.device('cpu')\n","print(device_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxc28oYnBSMc","executionInfo":{"status":"ok","timestamp":1703561094844,"user_tz":-330,"elapsed":967,"user":{"displayName":"abdul rasool","userId":"13975637965595716262"}},"outputId":"5ceeddab-971b-4649-edbd-3d08672b4c80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["## Loading Model 2: Finetuned model"],"metadata":{"id":"EK_ndel2xc2Z"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","  # Load the fine-tuned model and tokenizer\n","model_path = \"/content/drive/MyDrive/Youtube_video_classifier/model_2\"\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","model_2 = AutoModelForSequenceClassification.from_pretrained(model_path)\n","model_2.to(device_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKwKwxrkDAaz","outputId":"06eb5dae-e9ea-410e-af0a-e6b152afd3cf","executionInfo":{"status":"ok","timestamp":1703561097183,"user_tz":-330,"elapsed":2341,"user":{"displayName":"abdul rasool","userId":"13975637965595716262"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#Function to make prediction from model_2\n","def predict_from_model_2(data,model=model_2):\n","  predictions = []\n","  descriptions = data[\"description\"]\n","  with torch.no_grad():\n","    for description in descriptions:\n","      inputs = tokenizer(description,truncation=True, max_length=512, return_tensors=\"pt\")\n","      inputs = inputs.to(device_name)\n","\n","      # Make a prediction\n","      outputs = model(**inputs)\n","\n","\n","      # Get the predicted class probabilities\n","      probabilities = outputs.logits.softmax(dim=1)\n","\n","      predictions.append(probabilities.cpu().detach().numpy().reshape(9,))\n","      torch.cuda.empty_cache()\n","\n","  return np.array(predictions)"],"metadata":{"id":"6JjqvWQ3B-Xa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = pd.read_csv(\"test_data.csv\")"],"metadata":{"id":"ZSaiTE25tUC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ME2ftqTB7REG","executionInfo":{"status":"ok","timestamp":1703561700073,"user_tz":-330,"elapsed":3,"user":{"displayName":"abdul rasool","userId":"13975637965595716262"}},"outputId":"21c7beea-f89b-4585-aa92-bdc2fa5bd2a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["940"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["predictions_2 = predict_from_model_2(test_data)"],"metadata":{"id":"zr2gt-qJtwkF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocessing(df):\n","  description_with_tags=[]\n","  df = df[[\"category\",\"category_label\",\"description\",\"tags\"]]\n","  for index, row in df.iterrows():\n","    s=row[\"description\"]\n","    if not pd.isnull(row[\"tags\"]):\n","      s = s + row[\"tags\"]\n","    s=re.sub(r'http\\S+', '', s)\n","    s=re.findall(r'\\w+', s.lower())\n","    s_dummy = []\n","    for word in s:                                 #removing all numerical digits from words\n","      res = ''.join([i for i in word if not i.isdigit()])\n","      if len(res)>0:s_dummy.append(res)\n","    s = s_dummy\n","    s = [lemmatizer.lemmatize(w) for w in s if w not in eng_stopwords] #Removing stopwords and lemmatisation\n","    description_with_tags.append(s)\n","\n","  data = df.copy()\n","  data.loc[:,(\"description_with_tags\")]=description_with_tags\n","\n","  return data"],"metadata":{"id":"ET0v7MZ5D7oU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loading Model 1: Neural Network"],"metadata":{"id":"-VbD3BDjx1Lf"}},{"cell_type":"code","source":["with open('vocabulary_model_1.pkl', 'rb') as fp:\n","    vocabulary_model_1 = pickle.load(fp)\n","model_1 = tf.keras.models.load_model('model_1.keras')"],"metadata":{"id":"usHNanlKJbDY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Function to make prediction from model_1\n","def predict_from_model_1(data,model=model_1,vocab_dict=vocabulary_model_1):\n","  max_len = 1197\n","  descriptions = data[\"description_with_tags\"]\n","  padded_descriptions = []\n","  for description in descriptions:\n","    unk_ID = vocab_dict['[UNK]']\n","\n","    # First convert the words to integers by looking up the vocab_dict\n","    tensor = [vocab_dict.get(k,unk_ID) for k in description]\n","\n","    if len(tensor) > max_len: return tensor[:max_len]\n","\n","    # Then pad the tensor with zeroes up to the length max_len\n","    padded_tensor = tensor + [0]*(max_len-len(tensor))\n","\n","    padded_descriptions.append(padded_tensor)\n","  inputs = np.array(padded_descriptions)\n","  predictions = model.predict(inputs, verbose=False)\n","  return predictions"],"metadata":{"id":"JttNZPwwKRKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_1 = predict_from_model_1(preprocessing(test_data))"],"metadata":{"id":"OJ-bp3j3MlWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loading files for Model 0: Naive_Bayes_Classifier"],"metadata":{"id":"0sgOLcgVyHj1"}},{"cell_type":"code","source":["with open('vocabulary_model_0.pkl', 'rb') as fp:\n","    vocabulary_model_0 = pickle.load(fp)\n","with open('word_category_probabilities.pkl', 'rb') as fp:\n","    word_category_probabilities = pickle.load(fp)\n","with open('prior_probabilities.pkl', 'rb') as fp:\n","    prior_probabilities = pickle.load(fp)"],"metadata":{"id":"jaLs00L4NVin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Function to make prediction from model_0\n","def predict_from_model_0(data,vocabulary = vocabulary_model_0,word_category_probabilities=word_category_probabilities,prior_probabilities=prior_probabilities):\n","  categories = ['music','sports','gaming','education','film/animation','entertainment','news and politics','comedy','other']\n","  prediction = []\n","  for s in data[\"description_with_tags\"]:\n","    prob = []\n","\n","    for cat in categories:\n","      ans = 0\n","      for word in s:\n","        if word not in vocabulary: continue\n","        word_cat_prob = word_category_probabilities[word][cat]\n","        ans += np.log10(word_cat_prob)\n","      ans +=  np.log10(prior_probabilities[cat])\n","      prob.append(ans)\n","    logits = np.array(prob)\n","    prediction.append(tf.nn.softmax(tf.convert_to_tensor(logits)).numpy())\n","  return np.array(prediction)"],"metadata":{"id":"Q5Pr5J_ZNxRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_0 = predict_from_model_0(preprocessing(test_data))"],"metadata":{"id":"vKyL5dG6TeDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_0.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANmzSCbQYB1_","executionInfo":{"status":"ok","timestamp":1703568590217,"user_tz":-330,"elapsed":563,"user":{"displayName":"abdul rasool","userId":"13975637965595716262"}},"outputId":"d15c9e6c-8bf0-4e33-a2d4-fb04c16ebb74"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(940, 9)"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["pred_0 = np.argmax(predictions_0,axis=1)\n","pred_1 = np.argmax(predictions_1,axis=1)\n","pred_2 = np.argmax(predictions_2,axis=1)"],"metadata":{"id":"fBcXVFvppgu6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Making Ensemble prediction using predictions from 3 models."],"metadata":{"id":"2zIbkDwnycIz"}},{"cell_type":"code","source":["from collections import Counter\n","pred = np.array([pred_2 , pred_1 , pred_0])\n","final_pred = []\n","for i in range (len(pred[0])):\n","  arr = pred[:,i]\n","  pr = Counter(arr).most_common(1)[-1][0]\n","  final_pred.append(pr)\n"],"metadata":{"id":"p2vU-8RZpvaN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Final accuracy\n","from sklearn.metrics import accuracy_score\n","acc = accuracy_score(true_values,final_pred)\n","acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nFy81gxoUHt","executionInfo":{"status":"ok","timestamp":1703570168301,"user_tz":-330,"elapsed":456,"user":{"displayName":"abdul rasool","userId":"13975637965595716262"}},"outputId":"e1e638e6-07dc-46f9-f259-323385dc0ecd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8148936170212766"]},"metadata":{},"execution_count":162}]},{"cell_type":"code","source":["#predictions from url\n","from Helper_functions import get_video_data\n","from collections import Counter\n","def predict_category(url,model0=predict_from_model_0,model1=predict_from_model_1,model2=predict_from_model_2):\n","  details = get_video_data(url)\n","  if (details==[None]*12):\n","    return None , None\n","  df = pd.DataFrame(data=[details],columns=[\"video_id\",\"category_Id\",\"category\",\"category_label\",\"title\",\"description\",\"tags\",\"viewCount\",\"likeCount\",\"dislikeCount\",\"commentCount\",\"video_comments\"])\n","  df.loc[:,('tags')]=str(df.loc[:,('tags')])\n","  category = df[\"category\"][0]\n","  if pd.isnull(df[\"description\"][0]):\n","    return None , category\n","  predictions_2 = predict_from_model_2(df)\n","  predictions_1 = predict_from_model_1(preprocessing(df))\n","  predictions_0 = predict_from_model_0(preprocessing(df))\n","  pred_0 = np.argmax(predictions_0,axis=1)\n","  pred_1 = np.argmax(predictions_1,axis=1)\n","  pred_2 = np.argmax(predictions_2,axis=1)\n","  pred = np.array([pred_2 , pred_1 , pred_0])\n","  final_pred = []\n","  for i in range (len(pred[0])):\n","    arr = pred[:,i]\n","    pr = Counter(arr).most_common(1)[-1][0]\n","    final_pred.append(pr)\n","  categories = ['music','sports','gaming','education','film/animation','entertainment','news and politics','comedy','other']\n","  return categories[final_pred[0]],category\n","\n","\n"],"metadata":{"id":"T2IO-tSJpCBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paste url here and run the below cell to get prediction.\n","url = 'https://www.youtube.com/watch?v=prmmCg5bKxA'\n","predicted_category , original_category = predict_category(url)"],"metadata":{"id":"JskEw-EswEix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if (not predicted_category) and (not original_category):\n","  print(\"Sorry! Not able to fetch data from given url. Try with another url\")\n","else:\n","  if not predicted_category: print(\"No description is given for the video\")\n","  else : print(f\"The category predicted by the model using description and tags is : {predicted_category}\")\n","  print(f\"The actual category of the video is : {original_category} (from youtube data)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZLE4ycAwW9q","executionInfo":{"status":"ok","timestamp":1703572304214,"user_tz":-330,"elapsed":26,"user":{"displayName":"abdul rasool","userId":"13975637965595716262"}},"outputId":"3afdfc1b-bf8e-434a-9f6b-f79cbf31a9ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The category predicted by the model using description and tags is : music\n","The actual category of the video is : music (from youtube data)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"u2getJ7rw3oo"},"execution_count":null,"outputs":[]}]}